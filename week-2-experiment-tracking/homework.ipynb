{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34221967-3591-4407-a25e-ba7306e64d8f",
   "metadata": {},
   "source": [
    "# Homework Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0af9fe-726e-4200-93a0-3524ba827000",
   "metadata": {},
   "source": [
    "## Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c69698-7be1-4d76-b90a-69b9f303954c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow, version 1.26.1\n"
     ]
    }
   ],
   "source": [
    "!mlflow --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9f1d9-acb6-46f7-87b7-a8f220e6b996",
   "metadata": {},
   "source": [
    "## Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159cc052-2f67-43e9-b072-43457536c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_data.py --raw_data_path ../data/raw --dest_path ../data/preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f688eb-d572-4ca0-bb50-7030a6d34e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 15512\n",
      "drwxr-xr-x  6 syhamdani  staff   192B May 31 13:31 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  5 syhamdani  staff   160B May 31 13:30 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-r--r--  1 syhamdani  staff   298K May 31 13:31 dv.pkl\n",
      "-rw-r--r--  1 syhamdani  staff   2.7M May 31 13:31 test.pkl\n",
      "-rw-r--r--  1 syhamdani  staff   2.5M May 31 13:31 train.pkl\n",
      "-rw-r--r--  1 syhamdani  staff   2.1M May 31 13:31 valid.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ../data/preprocessed/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b903ae8-13b7-4793-b894-a15ceb5ef23a",
   "metadata": {},
   "source": [
    "## Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21c76df2-40b9-493e-b6ec-ad5f146a0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022/05/31 19:45:26 INFO mlflow.tracking.fluent: Experiment with name 'green-taxi-experiment' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --data_path ../data/preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e446f291-9d39-470f-a156-e15e57a42ae2",
   "metadata": {},
   "source": [
    "## Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73f1017d-3323-469d-97ce-400aaa110ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: mlflow server [OPTIONS]\n",
      "\n",
      "  Run the MLflow tracking server.\n",
      "\n",
      "  The server listens on http://localhost:5000 by default and only accepts\n",
      "  connections from the local machine. To let the server accept connections\n",
      "  from other machines, you will need to pass ``--host 0.0.0.0`` to listen on\n",
      "  all network interfaces (or a specific interface address).\n",
      "\n",
      "Options:\n",
      "  --backend-store-uri PATH     URI to which to persist experiment and run\n",
      "                               data. Acceptable URIs are SQLAlchemy-compatible\n",
      "                               database connection strings (e.g.\n",
      "                               'sqlite:///path/to/file.db') or local\n",
      "                               filesystem URIs (e.g.\n",
      "                               'file:///absolute/path/to/directory'). By\n",
      "                               default, data will be logged to the ./mlruns\n",
      "                               directory.\n",
      "  --default-artifact-root URI  Directory in which to store artifacts for any\n",
      "                               new experiments created. For tracking server\n",
      "                               backends that rely on SQL, this option is\n",
      "                               required in order to store artifacts. Note that\n",
      "                               this flag does not impact already-created\n",
      "                               experiments with any previous configuration of\n",
      "                               an MLflow server instance. By default, data\n",
      "                               will be logged to the mlflow-artifacts:/ uri\n",
      "                               proxy if the --serve-artifacts option is\n",
      "                               enabled. Otherwise, the default location will\n",
      "                               be ./mlruns.\n",
      "  --serve-artifacts            If specified, enables serving of artifact\n",
      "                               uploads, downloads, and list requests by\n",
      "                               routing these requests to the storage location\n",
      "                               that is specified by '--artifact-destination'\n",
      "                               directly through a proxy. The default location\n",
      "                               that these requests are served from is a local\n",
      "                               './mlartifacts' directory which can be\n",
      "                               overridden via the '--artifacts-destination'\n",
      "                               argument. Default: False\n",
      "  --artifacts-only             If specified, configures the mlflow server to\n",
      "                               be used only for proxied artifact serving. With\n",
      "                               this mode enabled, functionality of the mlflow\n",
      "                               tracking service (e.g. run creation, metric\n",
      "                               logging, and parameter logging) is disabled.\n",
      "                               The server will only expose endpoints for\n",
      "                               uploading, downloading, and listing artifacts.\n",
      "                               Default: False\n",
      "  --artifacts-destination URI  The base artifact location from which to\n",
      "                               resolve artifact upload/download/list requests\n",
      "                               (e.g. 's3://my-bucket'). Defaults to a local\n",
      "                               './mlartifacts' directory. This option only\n",
      "                               applies when the tracking server is configured\n",
      "                               to stream artifacts and the experiment's\n",
      "                               artifact root location is http or mlflow-\n",
      "                               artifacts URI.\n",
      "  -h, --host HOST              The network address to listen on (default:\n",
      "                               127.0.0.1). Use 0.0.0.0 to bind to all\n",
      "                               addresses if you want to access the tracking\n",
      "                               server from other machines.\n",
      "  -p, --port INTEGER           The port to listen on (default: 5000).\n",
      "  -w, --workers TEXT           Number of gunicorn worker processes to handle\n",
      "                               requests (default: 4).\n",
      "  --static-prefix TEXT         A prefix which will be prepended to the path of\n",
      "                               all static paths.\n",
      "  --gunicorn-opts TEXT         Additional command line options forwarded to\n",
      "                               gunicorn processes.\n",
      "  --waitress-opts TEXT         Additional command line options for waitress-\n",
      "                               serve.\n",
      "  --expose-prometheus TEXT     Path to the directory where metrics will be\n",
      "                               stored. If the directory doesn't exist, it will\n",
      "                               be created. Activate prometheus exporter to\n",
      "                               expose metrics on /metrics endpoint.\n",
      "  --help                       Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!mlflow server --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f6e4b-2621-46fd-bbf3-9d2720ad7dea",
   "metadata": {},
   "source": [
    "## Q5\n",
    "\n",
    "(Look at the corresponding python script)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
